{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# running Region Based Analysis (RBA) - an hierarchical mixed effects models on the whole brain (aka a set of ROIs)\n",
    "\n",
    "A notebook to run an RBA on fMRI data.  \n",
    "OHBM Brainhack 2022 project  \n",
    "\n",
    "Authors:  \n",
    "Gang Chen [@afni-gangc](https://github.com/afni-gangc)  \n",
    "Christopher Nolan [@crnolan](https://github.com/crnolan)    \n",
    "Kelly Garner  [@kel-github](https://github.com/kel-github) \n",
    "Lea Waller  [@HippocampusGirl](https://github.com/HippocampusGirl)  \n",
    "Daniel Tomasz [@danieltomasz](https://github.com/danieltomasz)  \n",
    "\n",
    "Modelling task-based fMRI data often involves performing a GLM at each voxel and then correcting for many many many multiple comparisons.  \n",
    "\n",
    "Here instead, we first summarise the data at the region of interest (ROI) level, and then perform a single hierarchical mixed effects model on all the ROIs at once.  \n",
    "\n",
    "This provides advantages typical of Bayesian hiearchal modelling; information at upper levels of the hierarchy (e.g. across ROIs) can help inform estimates at lower levels (the estimate for each ROI) - aka shrinkage - and we avoid the multiple comparisons problem by instead providing the strength of evidenve for the effect of interest at each ROI.  \n",
    "\n",
    "For a comprehensive introduction to this approach, see [this paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6635105/) and [this paper](https://apertureneuropub.cloud68.co/articles/46/index.html) by Gang Chen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that you have followed the installation instructions detailed in the repo [ReadMe](https://github.com/crnolan/pyrba/blob/main/README.md) doc.  \n",
    "\n",
    "**What we assume has happened before now**  \n",
    "\n",
    "You have run an experiment manipulating or measuring a particular variable. For our example we are assuming we have collected theory of mind (ToM) measures and have fMRI data from participants performing a task.  \n",
    "\n",
    "We want to know the association between ToM and activity in each of our ROIs. We perform a first-level analysis for each participant x voxel, and then for each ROI we average the effect of interest (e.g. a beta-coefficient or correlation score) across voxels.  \n",
    "\n",
    "This produces a dataset containing the following fields:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "subject | ROI | y | x  \n",
    "\n",
    "- x:  predictor variable (in this example a theory of mind score) (float)  \n",
    "- y = DV of interest from first level analysis - e.g. mu beta coefficient from region of interest (ROI) (float)  \n",
    "- ROI: the name of the region of interest (ROI) (string)  \n",
    "- subject: ID (string) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "import xarray as xr\n",
    "import bambi as bmb\n",
    "sns.set_theme(style='darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### next we load the data  \n",
    "\n",
    "We have a nice small set in the repo called 'data.txt' that you can try this on  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.txt', delimiter = '\\s')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define the model. Luckily for us, Tal Yarkoni & Jake Westfall developed this awesome [Bambi package](https://osf.io/rv7sn) which allows us to specify our linear mixed effects model using the notation we know so well in the neurosciences and social sciences more broadly (If you don't know the notation then see [this excellent introduction](https://bodo-winter.net/tutorial/bw_LME_tutorial2.pdf) from Bodo Winter). The package takes our formula and specifies our model in [PyMC](https://www.pymc.io/welcome.html) parlance, ready for passing to PyMC.  \n",
    "\n",
    "We define a model where our data (_y_) is predicted by our ToM measure (_x_), an intercept for each subject (_(1|subject)_), and a ToM x ROI interaction (_(x|ROI)_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = bmb.Model(\"y ~ x + (1|subject) + (x|ROI)\", data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then fit the model using PyMC. We are going to use the default priors (see the model graph below), and the No U-Turn Sampler ([NUTS](https://arxiv.org/abs/1111.4246)). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted = model.fit(tune=4000, \n",
    "                   draws=1000, \n",
    "                   chains=16, \n",
    "                   method='nuts_numpyro',\n",
    "                   nuts_kwargs=dict(max_tree_depth=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A nice feature of PyMC is that we can easily print the model graph, which shows us the assumptions we've made about the parameters in our model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, we assume that the random effects from the model come from normal distributions whose variance is drawn from a half normal (note this deviates from the original implementation in R, but we are working on this). Next we plot the psoterior estimates, and the chains to check that the model converged.  \n",
    "\n",
    "We also print out a summary of the model. We want to check the $\\hat{R}$ is around 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(fitted, figsize=(20, 35))\n",
    "az.summary(fitted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to check the results look somewhat like the output from Gang's original R implementation, so what follows is some data-wrangling and then a plot comparison..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rois = fitted['posterior']['x|ROI'].stack(y=['draw', 'chain']).to_pandas().transpose()\n",
    "rois.columns.name = 'ROI'\n",
    "rois = rois.stack()\n",
    "rois.name = 'value'\n",
    "rois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_means = rois.groupby(['ROI']).mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_df = rois.to_frame()\n",
    "roi_df['roi_mean'] = roi_df.groupby(['ROI']).transform('mean')\n",
    "roi_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('pyrba')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "95259738a94fadfb9c6d8d90e5e59da053d9447eca1336664fb8ce3011d95d00"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
